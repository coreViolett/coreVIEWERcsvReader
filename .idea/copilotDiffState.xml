<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/tests/test_core_viewer_csv_reader.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/tests/test_core_viewer_csv_reader.py" />
              <option name="originalContent" value="import os&#10;import io&#10;import unittest&#10;import tempfile&#10;from pathlib import Path&#10;&#10;import pandas as pd&#10;&#10;from src.coreviewercsvreader.core_viewer_csv_reader import (&#10;    _drop_empty_last_column,&#10;    _get_line_containing,&#10;    _fix_csv_file,&#10;    read_coresensing_csv,&#10;    read_many,&#10;    to_parquet,&#10;)&#10;&#10;&#10;class TestDropEmptyLastColumn(unittest.TestCase):&#10;    def test_drop_when_last_all_na(self):&#10;        # last col all NaN -&gt; drop&#10;        df = pd.DataFrame({&quot;a&quot;: [1, 2], &quot;b&quot;: [None, None]})&#10;        out = _drop_empty_last_column(df)&#10;        self.assertListEqual(list(out.columns), [&quot;a&quot;])  # dropped&#10;&#10;    def test_drop_when_last_all_empty_strings(self):&#10;        # last col all empty strings -&gt; drop&#10;        df = pd.DataFrame({&quot;a&quot;: [1], &quot;b&quot;: [&quot;&quot;]})&#10;        out = _drop_empty_last_column(df)&#10;        self.assertListEqual(list(out.columns), [&quot;a&quot;])  # dropped&#10;&#10;    def test_keep_when_last_has_value(self):&#10;        # last col has value -&gt; keep&#10;        df = pd.DataFrame({&quot;a&quot;: [1], &quot;b&quot;: [&quot;x&quot;]})&#10;        out = _drop_empty_last_column(df)&#10;        self.assertListEqual(list(out.columns), [&quot;a&quot;, &quot;b&quot;])  # kept&#10;&#10;    def test_empty_df(self):&#10;        # no columns -&gt; unchanged&#10;        df = pd.DataFrame()&#10;        out = _drop_empty_last_column(df)&#10;        self.assertEqual(out.shape, (0, 0))&#10;&#10;&#10;class TestGetLineContaining(unittest.TestCase):&#10;    def test_find_single_needle(self):&#10;        with tempfile.NamedTemporaryFile(&quot;w+&quot;, delete=False) as f:&#10;            p = Path(f.name)&#10;            f.write(&quot;alpha\n.beta\nSensordata here\n&quot;)&#10;        try:&#10;            idx = _get_line_containing(p, &quot;Sensordata&quot;)&#10;            self.assertEqual(idx, 2)&#10;        finally:&#10;            p.unlink(missing_ok=True)&#10;&#10;    def test_find_any_of_multiple_needles(self):&#10;        with tempfile.NamedTemporaryFile(&quot;w+&quot;, delete=False) as f:&#10;            p = Path(f.name)&#10;            f.write(&quot;foo\nbar\nbaz\n&quot;)&#10;        try:&#10;            idx = _get_line_containing(p, [&quot;nope&quot;, &quot;bar&quot;])  # any match&#10;            self.assertEqual(idx, 1)&#10;        finally:&#10;            p.unlink(missing_ok=True)&#10;&#10;    def test_not_found_returns_minus_one(self):&#10;        with tempfile.NamedTemporaryFile(&quot;w+&quot;, delete=False) as f:&#10;            p = Path(f.name)&#10;            f.write(&quot;foo\nbar\n&quot;)&#10;        try:&#10;            self.assertEqual(_get_line_containing(p, &quot;zzz&quot;), -1)&#10;        finally:&#10;            p.unlink(missing_ok=True)&#10;&#10;&#10;class TestFixCsvFile(unittest.TestCase):&#10;    def test_adds_comma_to_description_line(self):&#10;        # build a small file with Sensordata marker and description line&#10;        content = &quot;Header\nSensordata\nDescription without comma\n1,2,3\n&quot;&#10;        with tempfile.NamedTemporaryFile(&quot;w+&quot;, delete=False) as f:&#10;            p = Path(f.name)&#10;            f.write(content)&#10;        try:&#10;            changed = _fix_csv_file(p)&#10;            self.assertTrue(changed)&#10;            # verify the description line ends with a comma now&#10;            txt = p.read_text()&#10;            self.assertIn(&quot;Description without comma,\n&quot;, txt)&#10;            # idempotent second run&#10;            changed2 = _fix_csv_file(p)&#10;            self.assertFalse(changed2)&#10;        finally:&#10;            p.unlink(missing_ok=True)&#10;&#10;    def test_returns_false_when_marker_missing(self):&#10;        content = &quot;no marker here\n&quot;&#10;        with tempfile.NamedTemporaryFile(&quot;w+&quot;, delete=False) as f:&#10;            p = Path(f.name)&#10;            f.write(content)&#10;        try:&#10;            changed = _fix_csv_file(p)&#10;            self.assertFalse(changed)&#10;            self.assertEqual(p.read_text(), content)&#10;        finally:&#10;            p.unlink(missing_ok=True)&#10;&#10;&#10;class TestPublicApis(unittest.TestCase):&#10;    def setUp(self):&#10;        # sample CSV from repo&#10;        base = Path(__file__).parent / &quot;testdata&quot;&#10;        self.sample_csv = base / &quot;1-01107_2025-10-24_16-14-56.csv&quot;&#10;        self.sample_csv_eu = base / &quot;1-01107_2025-10-24_16-14-56_eu.csv&quot;&#10;        self.assertTrue(self.sample_csv.exists(), f&quot;Missing test file: {self.sample_csv}&quot;)&#10;        self.assertTrue(self.sample_csv_eu.exists(), f&quot;Missing test file: {self.sample_csv_eu}&quot;)&#10;&#10;    def test_read_coresensing_csv_basic(self):&#10;        df = read_coresensing_csv(self.sample_csv)&#10;        self.assertGreaterEqual(len(df), 1)  # has rows&#10;        self.assertGreaterEqual(df.shape[1], 1)  # has cols&#10;&#10;    def test_read_coresensing_csv_eu_separator(self):&#10;        # ensure EU file with ';' is parsed and header detected&#10;        df = read_coresensing_csv(self.sample_csv_eu)&#10;        self.assertIn(&quot;Time in ms&quot;, df.columns)&#10;        self.assertGreaterEqual(len(df), 1)&#10;        self.assertGreaterEqual(df.shape[1], 2)&#10;&#10;    def test_read_many_concat_and_source(self):&#10;        df = read_many([self.sample_csv, self.sample_csv], add_source=True)&#10;        self.assertIn(&quot;__source__&quot;, df.columns)&#10;        # two sources, but same path value&#10;        self.assertEqual(df[&quot;__source__&quot;].nunique(), 1)&#10;        # concatenated rows&#10;        self.assertGreaterEqual(len(df), 2)&#10;&#10;    def test_read_many_empty_input(self):&#10;        df = read_many([])&#10;        self.assertEqual(df.shape, (0, 0))&#10;&#10;    def test_to_parquet_roundtrip_if_engine_available(self):&#10;        # skip if no parquet engine available&#10;        engine_available = False&#10;        try:&#10;            import pyarrow  # noqa: F401&#10;            engine_available = True&#10;        except Exception:&#10;            try:&#10;                import fastparquet  # noqa: F401&#10;                engine_available = True&#10;            except Exception:&#10;                engine_available = False&#10;&#10;        if not engine_available:&#10;            self.skipTest(&quot;No parquet engine installed&quot;)&#10;&#10;        df = read_coresensing_csv(self.sample_csv)&#10;        with tempfile.TemporaryDirectory() as tmp:&#10;            out = Path(tmp) / &quot;out.parquet&quot;&#10;            to_parquet(df, out)&#10;            self.assertTrue(out.exists())&#10;            # ensure it can be read back&#10;            back = pd.read_parquet(out)&#10;            self.assertEqual(len(back), len(df))&#10;            self.assertEqual(back.shape[1], df.shape[1])&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    unittest.main()&#10;" />
              <option name="updatedContent" value="import io&#10;from pathlib import Path&#10;&#10;import pandas as pd&#10;import pytest&#10;&#10;from src.coreviewercsvreader.core_viewer_csv_reader import (&#10;    _drop_empty_last_column,&#10;    _get_line_containing,&#10;    _fix_csv_file,&#10;    read_coresensing_csv,&#10;    read_many,&#10;    to_parquet,&#10;)&#10;&#10;&#10;# ---- _drop_empty_last_column ----&#10;&#10;def test_drop_when_last_all_na():&#10;    df = pd.DataFrame({&quot;a&quot;: [1, 2], &quot;b&quot;: [None, None]})&#10;    out = _drop_empty_last_column(df)&#10;    assert list(out.columns) == [&quot;a&quot;]&#10;&#10;&#10;def test_drop_when_last_all_empty_strings():&#10;    df = pd.DataFrame({&quot;a&quot;: [1], &quot;b&quot;: [&quot;&quot;]})&#10;    out = _drop_empty_last_column(df)&#10;    assert list(out.columns) == [&quot;a&quot;]&#10;&#10;&#10;def test_keep_when_last_has_value():&#10;    df = pd.DataFrame({&quot;a&quot;: [1], &quot;b&quot;: [&quot;x&quot;]})&#10;    out = _drop_empty_last_column(df)&#10;    assert list(out.columns) == [&quot;a&quot;, &quot;b&quot;]&#10;&#10;&#10;def test_empty_df():&#10;    df = pd.DataFrame()&#10;    out = _drop_empty_last_column(df)&#10;    assert out.shape == (0, 0)&#10;&#10;&#10;# ---- _get_line_containing ----&#10;&#10;def test_find_single_needle(tmp_path: Path):&#10;    p = tmp_path / &quot;f.txt&quot;&#10;    p.write_text(&quot;alpha\n.beta\nSensordata here\n&quot;, encoding=&quot;utf-8&quot;)&#10;    idx = _get_line_containing(p, &quot;Sensordata&quot;)&#10;    assert idx == 2&#10;&#10;&#10;def test_find_any_of_multiple_needles(tmp_path: Path):&#10;    p = tmp_path / &quot;g.txt&quot;&#10;    p.write_text(&quot;foo\nbar\nbaz\n&quot;, encoding=&quot;utf-8&quot;)&#10;    idx = _get_line_containing(p, [&quot;nope&quot;, &quot;bar&quot;])&#10;    assert idx == 1&#10;&#10;&#10;def test_not_found_returns_minus_one(tmp_path: Path):&#10;    p = tmp_path / &quot;h.txt&quot;&#10;    p.write_text(&quot;foo\nbar\n&quot;, encoding=&quot;utf-8&quot;)&#10;    assert _get_line_containing(p, &quot;zzz&quot;) == -1&#10;&#10;&#10;# ---- _fix_csv_file ----&#10;&#10;def test_adds_comma_to_description_line(tmp_path: Path):&#10;    # Build a tiny file with marker and a description line&#10;    content = &quot;Header\nSensordata\nDescription without comma\n1,2,3\n&quot;&#10;    p = tmp_path / &quot;data.csv&quot;&#10;    p.write_text(content, encoding=&quot;utf-8&quot;)&#10;&#10;    changed = _fix_csv_file(p)&#10;    assert changed is True&#10;&#10;    txt = p.read_text(encoding=&quot;utf-8&quot;)&#10;    assert &quot;Description without comma,\n&quot; in txt&#10;&#10;    # Idempotent second run&#10;    changed2 = _fix_csv_file(p)&#10;    assert changed2 is False&#10;&#10;&#10;def test_returns_false_when_marker_missing(tmp_path: Path):&#10;    p = tmp_path / &quot;no_marker.csv&quot;&#10;    content = &quot;no marker here\n&quot;&#10;    p.write_text(content, encoding=&quot;utf-8&quot;)&#10;&#10;    changed = _fix_csv_file(p)&#10;    assert changed is False&#10;    assert p.read_text(encoding=&quot;utf-8&quot;) == content&#10;&#10;&#10;# ---- public APIs ----&#10;&#10;def _data_paths() -&gt; tuple[Path, Path]:&#10;    base = Path(__file__).parent / &quot;testdata&quot;&#10;    csv = base / &quot;1-01107_2025-10-24_16-14-56.csv&quot;&#10;    csv_eu = base / &quot;1-01107_2025-10-24_16-14-56_eu.csv&quot;&#10;    assert csv.exists(), f&quot;Missing test file: {csv}&quot;&#10;    assert csv_eu.exists(), f&quot;Missing test file: {csv_eu}&quot;&#10;    return csv, csv_eu&#10;&#10;&#10;def test_read_coresensing_csv_basic():&#10;    csv, _ = _data_paths()&#10;    df = read_coresensing_csv(csv)&#10;    assert len(df) &gt;= 1&#10;    assert df.shape[1] &gt;= 1&#10;&#10;&#10;def test_read_coresensing_csv_eu_separator():&#10;    _, csv_eu = _data_paths()&#10;    df = read_coresensing_csv(csv_eu)&#10;    assert &quot;Time in ms&quot; in df.columns&#10;    assert len(df) &gt;= 1&#10;    assert df.shape[1] &gt;= 2&#10;&#10;&#10;def test_read_many_concat_and_source():&#10;    csv, _ = _data_paths()&#10;    df = read_many([csv, csv], add_source=True)&#10;    assert &quot;__source__&quot; in df.columns&#10;    # Two sources but same path value&#10;    assert df[&quot;__source__&quot;].nunique() == 1&#10;    # Concatenated rows&#10;    assert len(df) &gt;= 2&#10;&#10;&#10;def test_read_many_empty_input():&#10;    df = read_many([])&#10;    assert df.shape == (0, 0)&#10;&#10;&#10;def test_to_parquet_roundtrip_if_engine_available(tmp_path: Path):&#10;    # Skip if no parquet engine&#10;    have_engine = True&#10;    try:&#10;        import pyarrow  # noqa: F401&#10;    except Exception:&#10;        try:&#10;            import fastparquet  # noqa: F401&#10;        except Exception:&#10;            have_engine = False&#10;&#10;    if not have_engine:&#10;        pytest.skip(&quot;No parquet engine installed&quot;)&#10;&#10;    csv, _ = _data_paths()&#10;    df = read_coresensing_csv(csv)&#10;    out = tmp_path / &quot;out.parquet&quot;&#10;    to_parquet(df, out)&#10;    assert out.exists()&#10;&#10;    back = pd.read_parquet(out)&#10;    assert len(back) == len(df)&#10;    assert back.shape[1] == df.shape[1]&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>